{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32b000b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hashed_id', 'lat', 'lon', 'time', 'polygon_name', 'geom', 'datetime']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from skmob import TrajDataFrame\n",
    "from skmob.preprocessing import detection\n",
    "# 1. Import necessary libraries\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely import wkb\n",
    "from pathlib import Path\n",
    "\n",
    "# 2. Read the CSV file containing trajectory data\n",
    "csv_path = Path(r\"\\\\tsclient\\D\\Siyu Zhao\\data\\Auckland region park\\waitakere_trajectories.csv\")\n",
    "\n",
    "\n",
    "df = pd.read_csv(\n",
    "    csv_path,\n",
    "    sep=\",\",            \n",
    "    header=0,\n",
    "    dtype={\n",
    "        \"hashed_id\": \"string\",\n",
    "        \"lat\": \"float64\",          \n",
    "        \"lon\": \"float64\",          \n",
    "        \"time\": \"int64\",           \n",
    "        \"polygon_name\": \"category\",\n",
    "        \"geom\": \"string\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# 3. change unix_timestamp to datetime\n",
    "df[\"datetime\"] = pd.to_datetime(df[\"time\"], unit=\"s\", utc=True) \n",
    "\n",
    "# # 4. Convert the WKB geometry column to a GeoDataFrame\n",
    "# df[\"geometry\"] = df[\"geom\"].apply(lambda x: wkb.loads(bytes.fromhex(x))) # Convert WKB hex string to Shapely geometry\n",
    "# gdf = gpd.GeoDataFrame(df, geometry=\"geometry\", crs=\"EPSG:4326\")  # Set the coordinate reference system to WGS 84\n",
    "\n",
    "# 5. print\n",
    "print(df.columns.tolist()) # Display the list of columns in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd1a094",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Siyu\\anaconda3\\envs\\mobility310\\lib\\site-packages\\skmob\\preprocessing\\detection.py:102: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  stdf = tdf.groupby(groupby, group_keys=False, as_index=False).apply(_stay_locations_trajectory, stop_radius=stop_radius,\n"
     ]
    }
   ],
   "source": [
    "# stay points detection\n",
    "df = df.rename(columns={\"lon\": \"lng\"})  # Rename 'lon' to 'lng' for consistency with skmob\n",
    "\n",
    "# 6. Create a TrajDataFrame from the DataFrame\n",
    "tdf = TrajDataFrame(\n",
    "    df[[\"hashed_id\", \"datetime\", \"lat\", \"lng\"]],\n",
    "    user_id='hashed_id',\n",
    "    timestamp=True\n",
    ")\n",
    "\n",
    "# 7. Detect stay locations using skmob's detection module\n",
    "stdf = detection.stay_locations(\n",
    "    tdf,\n",
    "    minutes_for_a_stop=5, \n",
    "    spatial_radius_km=0.05, \n",
    "    leaving_time=True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b85b1cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         uid                  datetime  \\\n",
      "0   0001ebc00454fd08b2f233205c357b1f35a8a5fe 2019-05-16 06:03:57+00:00   \n",
      "5   0004ec53405b3ce3052846a0519058689fc839af 2020-09-27 04:09:32+00:00   \n",
      "6   0004ec53405b3ce3052846a0519058689fc839af 2020-09-27 04:14:39+00:00   \n",
      "9   0004ec53405b3ce3052846a0519058689fc839af 2020-09-27 04:33:30+00:00   \n",
      "10  0004ec53405b3ce3052846a0519058689fc839af 2020-09-27 04:39:37+00:00   \n",
      "\n",
      "     lat_left         lng           leaving_datetime  \\\n",
      "0  -36.954955  174.473730  2019-05-16 08:28:33+00:00   \n",
      "5  -36.954766  174.472970  2020-09-27 04:14:39+00:00   \n",
      "6  -36.952642  174.468510  2020-09-27 04:21:23+00:00   \n",
      "9  -36.953418  174.474422  2020-09-27 04:39:37+00:00   \n",
      "10 -36.949889  174.467558  2020-09-27 04:45:39+00:00   \n",
      "\n",
      "                             geometry  index_right          id   timestamp  \\\n",
      "0    POINT (19422326.78 -4432829.954)          896    79293437  1672816915   \n",
      "5   POINT (19422242.178 -4432803.625)          896    79293437  1672816915   \n",
      "6   POINT (19421745.693 -4432507.747)          970   398849119  1665005293   \n",
      "9   POINT (19422403.813 -4432615.845)          128  1321206363  1704169662   \n",
      "10   POINT (19421639.717 -4432124.26)         1470  1218808834  1698421177   \n",
      "\n",
      "   visible  ...  railway osm_type  wetland  building  building:levels  \\\n",
      "0    False  ...     None      way     None      None             None   \n",
      "5    False  ...     None      way     None      None             None   \n",
      "6    False  ...     None      way     None      None             None   \n",
      "9    False  ...     None     node     None      None             None   \n",
      "10   False  ...     None      way     None      None             None   \n",
      "\n",
      "   drinking_water  area surface  aeroway   distance  \n",
      "0            None  None    None     None   0.000000  \n",
      "5            None  None    None     None   0.000000  \n",
      "6            None  None    None     None   0.000000  \n",
      "9            None  None    None     None  48.104433  \n",
      "10           None  None    None  helipad   0.000000  \n",
      "\n",
      "[5 rows x 58 columns]\n",
      "['uid', 'datetime', 'lat_left', 'lng', 'leaving_datetime', 'geometry', 'index_right', 'id', 'timestamp', 'visible', 'version', 'tags', 'lon', 'changeset', 'lat_right', 'addr:city', 'addr:housenumber', 'addr:housename', 'addr:postcode', 'addr:street', 'email', 'name', 'opening_hours', 'operator', 'phone', 'ref', 'website', 'tourism', 'zoo', 'leisure', 'outdoor_seating', 'natural', 'amenity', 'bicycle_parking', 'fountain', 'internet_access', 'parking', 'source', 'start_date', 'wikipedia', 'shop', 'historic', 'memorial', 'access', 'foot', 'highway', 'lit', 'public_transport', 'railway', 'osm_type', 'wetland', 'building', 'building:levels', 'drinking_water', 'area', 'surface', 'aeroway', 'distance']\n",
      "(101125, 58)\n"
     ]
    }
   ],
   "source": [
    "# match stay points with POIs\n",
    "\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# 8. Read the POIs from a GeoPackage file\n",
    "pois_path = Path(r\"\\\\tsclient\\D\\Siyu Zhao\\data\\Auckland region park\\Auckland-parks-poi.gpkg\")\n",
    "pois = gpd.read_file(pois_path)\n",
    "\n",
    "# 9. Convert the stay points back to a DataFrame\n",
    "stdf['geometry'] = [Point(xy) for xy in zip(stdf['lng'], stdf['lat'])]  # Create Point geometries from lat/lng\n",
    "stay_gdf = gpd.GeoDataFrame(stdf, geometry='geometry', crs=\"EPSG:4326\") # Convert to GeoDataFrame with WGS 84 CRS\n",
    "\n",
    "stay_gdf = stay_gdf.to_crs(epsg=3857) # Convert to Web Mercator CRS\n",
    "pois = pois.to_crs(epsg=3857)         # Convert POIs to Web Mercator CRS\n",
    "\n",
    "# 10. Perform a spatial join to find the nearest POI for each stay point\n",
    "matched = gpd.sjoin_nearest(stay_gdf, pois, how=\"left\", distance_col=\"distance\")\n",
    "\n",
    "# 11. Filter matched results to keep only those within a certain distance \n",
    "matched = matched[matched[\"distance\"] <= 50]\n",
    "\n",
    "print(matched.head())  # Display the first few rows of the matched DataFrame\n",
    "print(matched.columns.tolist())  # Display the list of columns in the matched DataFrame\n",
    "print(matched.shape)  # Display the shape of the matched DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbe9b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "333279a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['uid', 'datetime', 'lat_left', 'lng', 'leaving_datetime', 'geometry', 'index_right', 'id', 'timestamp', 'visible', 'version', 'tags', 'lon', 'changeset', 'lat_right', 'addr:city', 'addr:housenumber', 'addr:housename', 'addr:postcode', 'addr:street', 'email', 'name', 'opening_hours', 'operator', 'phone', 'ref', 'website', 'tourism', 'zoo', 'leisure', 'outdoor_seating', 'natural', 'amenity', 'bicycle_parking', 'fountain', 'internet_access', 'parking', 'source', 'start_date', 'wikipedia', 'shop', 'historic', 'memorial', 'access', 'foot', 'highway', 'lit', 'public_transport', 'railway', 'osm_type', 'wetland', 'building', 'building:levels', 'drinking_water', 'area', 'surface', 'aeroway', 'distance', 'poi_type', 'poi_category']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 12. Define the tags for tourism and transport categories\n",
    "tourism_tags = {\n",
    "    \"tourism\": [\n",
    "        \"attraction\", \"viewpoint\",  \"museum\", \"gallery\",\n",
    "         \"sightseeing\", \"zoo\", \"theme_park\", \"aquarium\", \n",
    "    ],\n",
    "    \"leisure\": [\n",
    "        \"park\", \"nature_reserve\", \"garden\", \"playground\", \"picnic_site\", \"dog_park\",\n",
    "    ],\n",
    "    \"natural\": [\n",
    "        \"waterfall\", \"peak\", \"beach\", \"spring\", \"volcano\", \n",
    "        \"cave_entrance\" , \"wetland\", \"bay\" , \"valley\" ,\n",
    "        \"lake\", \"river\", \"stream\",\n",
    "    ],\n",
    "    \"sport\" : [\n",
    "        \"surfing\",\"scuba_diving\",\"fishing\",\"kayaking\",\"rowing\",\"rafting\",\n",
    "         \"climbing\",\"running\",\"trail_running\",\"mountain_biking\",\"orienteering\",\n",
    "        \"horse_riding\",\"equestrian\",\"paragliding\",\"beachvolleyball\",\"disc_golf\"\n",
    "    ],\n",
    "    \"amenity\": [\n",
    "        \"restaurant\", \"cafe\", \"bar\", \"pub\", \"fast_food\", \"ice_cream\", \"toilets\",\n",
    "        \"food_court\",\"bbq\",\"drinking_water\",\"shower\", \"bench\",\n",
    "        \"parking\", \"bicycle_parking\", \"ferry_terminal\",\"fuel\",\"bicycle_rental\", \"car_rental\",\"car_sharing\",\"taxi\"\n",
    "    ],\n",
    "    \"shop\": [\n",
    "        \"convenience\", \"supermarket\", \"bakery\", \"mall\",\n",
    "        \"outdoor\",\"sports\",\"surf\",\"diving\",\"bicycle\",\"camping\",\n",
    "        \"souvenir\",\"gift\",\"craft\",\n",
    "    ],\n",
    "    \"historic\": [ \"monument\", \"memorial\",\"milestone\", \"heritage\"],\n",
    "                        \n",
    "}\n",
    "\n",
    "transport_tags = {\n",
    "    \"highway\": [ \"bus_stop\",\"bus_station\"],\n",
    "    \"public_transport\": [\"bus_stop\", \"ferry\", \"train_station\",\"boarding_area\"],\n",
    "    \"railway\": [\"subway\",\"station\"],\n",
    "    \"aeroway\": [\"aerodrome\", \"helipad\"],\n",
    "    \"waterway\": [\"boat_ramp\",\"dock\"]\n",
    "}\n",
    "\n",
    "combined_tags = {**tourism_tags, **transport_tags} # Combine both dictionaries\n",
    "\n",
    "# 13.Create a reverse mapping from value to category\n",
    "value_to_category = {} \n",
    "for cat, values in combined_tags.items():\n",
    "    for val in values:\n",
    "        value_to_category[val] = cat\n",
    "\n",
    "# 14. Define a function to extract the POI type from the matched DataFrame\n",
    "def extract_poi_type(row):\n",
    "    for col in row.index:\n",
    "        if col in combined_tags:  # tourism, leisure, natural, etc.\n",
    "            tag_value = row[col]\n",
    "            if pd.notna(tag_value):\n",
    "                return tag_value  # e.g., \"park\"\n",
    "    return None\n",
    "\n",
    "# 15. Apply the function to extract the POI type for each row in the matched DataFrame\n",
    "matched[\"poi_type\"] = matched.apply(extract_poi_type, axis=1)\n",
    "# 16. Map the POI type to its category using the reverse mapping\n",
    "matched[\"poi_category\"] = matched[\"poi_type\"].map(value_to_category)\n",
    "\n",
    "print(matched.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "269dcda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['uid', 'datetime', 'lat_left', 'lng', 'leaving_datetime', 'geometry', 'index_right', 'id', 'name', 'lon', 'lat_right', 'distance', 'poi_type']\n",
      "                                         uid                  datetime  \\\n",
      "0   0001ebc00454fd08b2f233205c357b1f35a8a5fe 2019-05-16 06:03:57+00:00   \n",
      "5   0004ec53405b3ce3052846a0519058689fc839af 2020-09-27 04:09:32+00:00   \n",
      "6   0004ec53405b3ce3052846a0519058689fc839af 2020-09-27 04:14:39+00:00   \n",
      "9   0004ec53405b3ce3052846a0519058689fc839af 2020-09-27 04:33:30+00:00   \n",
      "10  0004ec53405b3ce3052846a0519058689fc839af 2020-09-27 04:39:37+00:00   \n",
      "\n",
      "     lat_left         lng           leaving_datetime  \\\n",
      "0  -36.954955  174.473730  2019-05-16 08:28:33+00:00   \n",
      "5  -36.954766  174.472970  2020-09-27 04:14:39+00:00   \n",
      "6  -36.952642  174.468510  2020-09-27 04:21:23+00:00   \n",
      "9  -36.953418  174.474422  2020-09-27 04:39:37+00:00   \n",
      "10 -36.949889  174.467558  2020-09-27 04:45:39+00:00   \n",
      "\n",
      "                             geometry  index_right          id  \\\n",
      "0    POINT (19422326.78 -4432829.954)          896    79293437   \n",
      "5   POINT (19422242.178 -4432803.625)          896    79293437   \n",
      "6   POINT (19421745.693 -4432507.747)          970   398849119   \n",
      "9   POINT (19422403.813 -4432615.845)          128  1321206363   \n",
      "10   POINT (19421639.717 -4432124.26)         1470  1218808834   \n",
      "\n",
      "                  name         lon  lat_right   distance    poi_type  \n",
      "0          Piha Domain         NaN        NaN   0.000000        park  \n",
      "5          Piha Domain         NaN        NaN   0.000000        park  \n",
      "6                 None         NaN        NaN   0.000000     parking  \n",
      "9   West Coast Gallery  174.474213  -36.95372  48.104433  attraction  \n",
      "10                None         NaN        NaN   0.000000     helipad  \n"
     ]
    }
   ],
   "source": [
    "# 17. Clean up the matched DataFrame to keep only relevant columns\n",
    "columns_to_keep = [\n",
    "    'uid', 'datetime', 'lat_left', 'lng', 'leaving_datetime', 'geometry',\n",
    "    'index_right', 'id', 'name','lon', 'lat_right', 'distance', 'poi_type'\n",
    "]\n",
    "matched_cleaned = matched[columns_to_keep]\n",
    "print(matched_cleaned.columns.tolist())\n",
    "print(matched_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78fee1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 18. Save the cleaned DataFrame to a CSV file\n",
    "matched_cleaned.to_csv(\n",
    "    Path(r\"\\\\tsclient\\D\\Siyu Zhao\\data\\Auckland region park\\matched_pois.csv\"),\n",
    "    index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mobility310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
