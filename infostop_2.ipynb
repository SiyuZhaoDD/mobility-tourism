{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e1ac39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "from shapely import wkb\n",
    "\n",
    "csv_path = Path(r\"D:\\Siyu Zhao\\data\\Auckland region park\\waitakere_trajectories.csv\")\n",
    "\n",
    "\n",
    "df = pd.read_csv(\n",
    "    csv_path,\n",
    "    sep=\",\",            \n",
    "    header=0,\n",
    "    dtype={\n",
    "        \"hashed_id\": \"string\",\n",
    "        \"lat\": \"float64\",          \n",
    "        \"lon\": \"float64\",          \n",
    "        \"time\": \"int64\",           \n",
    "        \"polygon_name\": \"category\",\n",
    "        \"geom\": \"string\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# 3. change unix_timestamp to datetime\n",
    "df[\"datetime\"] = pd.to_datetime(df[\"time\"], unit=\"s\", utc=True) \n",
    "df[\"datetime\"] = df[\"datetime\"].dt.tz_convert(\"Pacific/Auckland\")  # Convert to Auckland timezone\n",
    "df[\"timestamp\"] = df[\"datetime\"].apply(lambda x: x.timestamp())    \n",
    "\n",
    "# 4. Convert the WKB geometry column to a GeoDataFrame\n",
    "df[\"geometry\"] = df[\"geom\"].apply(lambda x: wkb.loads(bytes.fromhex(x))) # Convert WKB hex string to Shapely geometry\n",
    "\n",
    "\n",
    "# # 5. print\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f3896d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.reset_index(drop=True)  # Ensure clean index\n",
    "df[\"row_id\"] = df.index         # Add unique identifier for each row\n",
    "\n",
    "data = []\n",
    "row_ids = []\n",
    "\n",
    "for _, group in df.groupby(\"hashed_id\"):\n",
    "    group_sorted = group.sort_values(\"time\")\n",
    "    coords = group_sorted[[\"lat\", \"lon\", \"time\"]].to_numpy()\n",
    "    data.append(coords)\n",
    "    row_ids.extend(group_sorted[\"row_id\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004045c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Convert each user's trajectory into a NumPy array of shape (N, 3) with columns\n",
    "# data = [\n",
    "#     group.sort_values(\"time\")[[\"lat\", \"lon\", \"time\"]].to_numpy()\n",
    "#     for _, group in df.groupby(\"hashed_id\")\n",
    "# ]\n",
    "\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d55a65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from infostop import Infostop\n",
    "import numpy as np\n",
    "\n",
    "model = Infostop(\n",
    "    r1=200,                            # Maximum distance to stay in the same place (for a stop)\n",
    "    r2=100,                            # Maximum distance to group stops into one destination\n",
    "    min_staying_time= 10 * 60,         # The minimum time a person must stay within a small area to be considered a stop.最短停留时间（小于就不是停留点）\n",
    "    max_time_between= 24 * 60 * 60     # 24h The maximum time allowed between two nearby points to still count as the same stop. 最大停留时间（超过就分成多个停留）\n",
    ")\n",
    "\n",
    "labels = model.fit_predict(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d67545",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_labels = np.concatenate(labels)\n",
    "\n",
    "num_valid_stops = np.sum(all_labels != -1)\n",
    "\n",
    "print(f\"200m，100m，10min有效的停留点个数：{num_valid_stops}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefe487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualize import plot_map\n",
    "\n",
    "folmap = plot_map(\n",
    "    model,\n",
    "    display_data=\"unique_stationary\",\n",
    "    polygons=True,\n",
    "    heatmap=True,\n",
    "    scatter=True, \n",
    "    scatter_opacity= 0.1,\n",
    "    scatter_radius=3,\n",
    "    #tiles=\"CartoDB positron\",\n",
    "    tiles=\"OpenStreetMap\",\n",
    "    zoom_start=13\n",
    "\n",
    ")\n",
    "folmap.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dde7e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_labels = pd.DataFrame({\n",
    "    \"row_id\": row_ids,\n",
    "    \"destination_id\": all_labels\n",
    "})\n",
    "\n",
    "# Merge labels back\n",
    "df_result = df.merge(df_labels, on=\"row_id\", how=\"left\")\n",
    "# df_result_clean = df_result[df_result[\"destination_id\"] != -1]\n",
    "\n",
    "print(\"有效停留点标签数：\", np.sum(all_labels != -1))\n",
    "print(\"最终 merge 后的停留点数：\", len(df_result))\n",
    "print(df_result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0247fff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_path = r\"D:\\Siyu Zhao\\data\\Auckland region park\\infostop.csv\"\n",
    "df_result.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3197d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "path = Path(r\"D:\\Siyu Zhao\\data\\Auckland region park\\infostop.csv\")\n",
    "df_result = pd.read_csv(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfd0869",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: sort\n",
    "df_result = df_result.sort_values(by=[\"hashed_id\", \"timestamp\"]).reset_index(drop=True)\n",
    "\n",
    "# Step 2: detect new session (when hashed_id or destination_id change)\n",
    "df_result[\"prev_user\"] = df_result[\"hashed_id\"].shift(1)\n",
    "df_result[\"prev_dest\"] = df_result[\"destination_id\"].shift(1)\n",
    "\n",
    "df_result[\"new_session\"] = (\n",
    "    (df_result[\"hashed_id\"] != df_result[\"prev_user\"]) |\n",
    "    (df_result[\"destination_id\"] != df_result[\"prev_dest\"])\n",
    ").astype(int)\n",
    "\n",
    "# Step 3: define session id\n",
    "df_result[\"stay_session_id\"] = df_result[\"new_session\"].cumsum()\n",
    "\n",
    "# Step 4: aggregate session-level data\n",
    "session_df = (\n",
    "    df_result.groupby(\"stay_session_id\")\n",
    "    .agg(\n",
    "        hashed_id=(\"hashed_id\", \"first\"),\n",
    "        destination_id=(\"destination_id\", \"first\"),\n",
    "        start_ts=(\"timestamp\", \"min\"),\n",
    "        end_ts=(\"timestamp\", \"max\"),\n",
    "        point_count=(\"timestamp\", \"count\"),\n",
    "        lat=(\"lat\", \"mean\"),\n",
    "        lon=(\"lon\", \"mean\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Step 5: duration = end_ts - start_ts\n",
    "session_df[\"duration_minutes\"] = (session_df[\"end_ts\"] - session_df[\"start_ts\"]) / 60\n",
    "\n",
    "# Step 6: convert timestamps\n",
    "session_df[\"start_time\"] = pd.to_datetime(session_df[\"start_ts\"], unit=\"s\", utc=True).dt.tz_convert(\"Pacific/Auckland\")\n",
    "session_df[\"end_time\"] = pd.to_datetime(session_df[\"end_ts\"], unit=\"s\", utc=True).dt.tz_convert(\"Pacific/Auckland\")\n",
    "\n",
    "# Step 7: display result\n",
    "print(session_df[[\"hashed_id\", \"destination_id\", \"start_time\", \"end_time\", \"duration_minutes\", \"lat\", \"lon\"]].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ba735d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(session_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017e1496",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "session_df_clean = session_df[session_df[\"destination_id\"] != -1].copy()\n",
    "print(len(session_df_clean))\n",
    "print(len(session_df))\n",
    "print(session_df_clean[\"duration_minutes\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef28906",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = r\"D:\\Siyu Zhao\\data\\Auckland region park\\infostop_stay_duration.csv\"\n",
    "session_df_clean.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8539f367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(r\"D:\\Siyu Zhao\\data\\Auckland region park\\infostop.csv\")\n",
    "\n",
    "\n",
    "df.drop(columns=['prev_user', 'prev_dest', 'new_session', 'stay_session_id'], inplace=True)\n",
    "\n",
    "\n",
    "df.to_csv(r\"D:\\Siyu Zhao\\data\\Auckland region park\\infostop.csv\", index=False)\n",
    "\n",
    "print(len(df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
